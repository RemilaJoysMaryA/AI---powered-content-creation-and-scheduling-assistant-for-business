'''from flask import Flask, request, jsonify, render_template
from apscheduler.schedulers.background import BackgroundScheduler
import os
import pandas as pd
import feedparser
from bs4 import BeautifulSoup
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string
from datetime import datetime
from schedular import create_scheduler

# Initialize the Flask app
app = Flask(__name__)

# Set environment variables for GitHub token and model endpoint
os.environ['GITHUB_TOKEN'] = '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'
token = os.environ.get("GITHUB_TOKEN")
endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-3-mini-4k-instruct"

if token is None:
    raise ValueError("GITHUB_TOKEN environment variable is not set.")

# Initialize the Azure model client
client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(token))

# Scheduler configuration
scheduler = BackgroundScheduler()
scheduler.start()

nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
stop_words = set(stopwords.words('english'))
punctuation = set(string.punctuation)

# To store scheduled posts
scheduled_posts = []

# Load the training data
feed_data = pd.read_csv('Training_data3.csv')

# Function to fetch and parse RSS feeds based on domain
def fetch_rss_feeds(domain):
    rss_feed_urls = feed_data[feed_data['Domain'].str.lower() == domain.lower()]['URL'].tolist()
    all_data = []
    for url in rss_feed_urls:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                summary = BeautifulSoup(entry.summary, "html.parser").text if 'summary' in entry else ''
                all_data.append({
                    'title': entry.title,
                    'link': entry.link,
                    'published': entry.published,
                    'summary': summary
                })
        except Exception as e:
            print(f"Error processing URL {url}: {e}")
    return pd.DataFrame(all_data)

# Preprocess the summaries (text cleaning)
def preprocess_text(text):
    if pd.isnull(text):
        return ""
    tokens = word_tokenize(text.lower())
    cleaned_tokens = [word for word in tokens if word not in stop_words and word not in punctuation]
    return ' '.join(cleaned_tokens)

# Function to fine-tune based on domain
def train_model_on_domain(domain):
    rss_feed_data = fetch_rss_feeds(domain)
    if rss_feed_data.empty:
        return None

    # Remove duplicates and preprocess the summaries
    rss_feed_data = rss_feed_data.drop_duplicates()
    rss_feed_data['cleaned_summary'] = rss_feed_data['summary'].apply(preprocess_text)

    return rss_feed_data

# Function to generate content using the Azure-hosted model
def generate_content(prompt):
    try:
        messages = [
            SystemMessage(content="You are a helpful assistant."),
            UserMessage(content=prompt)
        ]
        
        response = client.complete(
            stream=True,
            messages=messages,
            model=model_name,
        )
        
        generated_content = ""
        for update in response:
            if update.choices:
                generated_content += update.choices[0].delta.content or ""
        
        if not generated_content:
            print("No content generated by the AI model.")
        return generated_content
    except Exception as e:
        print(f"Error generating content: {e}")
        return ""
 
def generate_content(prompt):
    try:
        print(f"Generating content for prompt: {prompt}")
        messages = [
            SystemMessage(content="You are a helpful assistant."),
            UserMessage(content=prompt)
        ]
        response = client.complete(
            stream=True,
            messages=messages,
            model=model_name,
        )
        generated_content = ""
        for update in response:
            if update.choices:
                generated_content += update.choices[0].delta.content or ""
        if not generated_content:
            raise ValueError("No content generated.")
        return generated_content
    except Exception as e:
        print(f"Error generating content: {e}")
        raise

    
# Scheduler job to generate content every minute
def scheduled_post_generation():
    prompt = "Write a blog on gaming."
    content = generate_content(prompt)
    if content:
        scheduled_posts.append(content)
        print(f"Generated post: {content}")
    else:
        print("Failed to generate content.")

# Route for scheduled posts page
@app.route('/sch')
def sch():
    return render_template('sch.html')

# Route to get the scheduled posts
@app.route('/get-scheduled-posts')
def get_scheduled_posts():
    return jsonify({"posts": scheduled_posts})

# Schedule the post generation function to run every minute
scheduler.add_job(func=scheduled_post_generation, trigger="interval", minutes=5)

@app.route('/schedule-post', methods=['POST'])
def schedule_post():
    data = request.json
    post_time = data.get('time')

    if not post_time:
        return jsonify({"error": "Time is required."}), 400

    try:
        # Parse the time from the user input
        scheduled_time = datetime.fromisoformat(post_time)

        # Calculate the delay for scheduling
        delay = (scheduled_time - datetime.now()).total_seconds()

        if delay < 0:
            return jsonify({"error": "Scheduled time must be in the future."}), 400

        # Schedule the job to run at the specified time
        scheduler.add_job(func=scheduled_post_generation, trigger='date', run_date=scheduled_time)

        return jsonify({"message": "Post scheduled successfully."}), 200
    except ValueError:
        return jsonify({"error": "Invalid date format."}), 400

@app.route('/chat')
def chat():
    return render_template('chat.html')

@app.route('/generate-content', methods=['POST'])
def generate_content_route():
    data = request.json
    print("Received Data:", data)

    if data is None:
        return jsonify({"error": "No data provided."}), 400

    user_domain = data.get('domain')
    user_prompt = data.get('prompt')

    if user_domain is None or user_prompt is None:
        return jsonify({"error": "Domain and prompt are required."}), 400

    seo_content = generate_content(f"Provide structured SEO optimization tips for the topic: {user_prompt}")
    if not seo_content:
        return jsonify({"error": "Failed to generate SEO content."}), 500

    blog_generation_prompt = (
        f"write SEO optimized blog on the topic: {user_prompt}\n\n"
        
    )
    blog_generated_content_with_seo = generate_content(blog_generation_prompt)

    social_media_content = generate_content(f"Create a social media post based on the blog topic: {user_prompt}")
    email_campaign_content = generate_content(f"Create a professional email campaign for the topic: {user_prompt}")

    return jsonify({
        "blog_content": blog_generated_content_with_seo or "No blog content generated.",
        "seo_tips": seo_content or "No SEO tips generated.",
        "social_media_post": social_media_content or "No social media post generated.",
        "email_campaign": email_campaign_content or "No email campaign content generated."
    })

if __name__ == '__main__':
    create_scheduler(app)
    app.run(debug=True)
'''

import spacy
from flask import Flask, request, jsonify, render_template
from apscheduler.schedulers.background import BackgroundScheduler
import os
import pandas as pd
import feedparser
from bs4 import BeautifulSoup
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string
from datetime import datetime
import requests


# Initialize Flask app
app = Flask(__name__)

# Set environment variables
os.environ['GITHUB_TOKEN'] = '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'
token = os.environ.get("GITHUB_TOKEN")
endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-3-mini-4k-instruct"

# WordPress API details and OAuth2 token
WORDPRESS_URL = "https://public-api.wordpress.com/rest/v1.1/sites/remilajoys5.wordpress.com/posts/new"
ACCESS_TOKEN = "oY)2Q(lFazT)PpFX&jC1Lv$TKTh(EAf3)l6dl2XDfm7I$kYDj$(oM!DjBN$2KxBm"  # Replace with your WordPress OAuth token


# To store scheduled posts
scheduled_posts = []

if token is None:
    raise ValueError("GITHUB_TOKEN environment variable is not set.")

# Azure model client initialization
client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(token))

# Scheduler configuration
scheduler = BackgroundScheduler()
scheduler.start()

# Load NLP model
nlp = spacy.load("en_core_web_md")

# Load training data
feed_data = pd.read_csv('Training_data3.csv')

# Extract unique domains
unique_domains = feed_data['Domain'].str.lower().unique()

# Function to fetch RSS feeds based on domain
def fetch_rss_feeds(domain):
    rss_feed_urls = feed_data[feed_data['Domain'].str.lower() == domain.lower()]['URL'].tolist()
    all_data = []
    for url in rss_feed_urls:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                summary = BeautifulSoup(entry.summary, "html.parser").text if 'summary' in entry else ''
                all_data.append({
                    'title': entry.title,
                    'link': entry.link,
                    'published': entry.published,
                    'summary': summary
                })
        except Exception as e:
            print(f"Error processing URL {url}: {e}")
    return pd.DataFrame(all_data)

# Function to preprocess text
def preprocess_text(text):
    stop_words = set(stopwords.words('english'))
    punctuation = set(string.punctuation)
    tokens = word_tokenize(text.lower())
    return ' '.join([word for word in tokens if word not in stop_words and word not in punctuation])

# NLP-based domain matching
def match_domain(user_input):
    user_doc = nlp(user_input.lower())
    max_similarity = 0
    best_match = None
    for domain in unique_domains:
        domain_doc = nlp(domain)
        similarity = user_doc.similarity(domain_doc)
        if similarity > max_similarity:
            max_similarity = similarity
            best_match = domain
    return best_match

# Function to fine-tune model on domain
def train_model_on_domain(user_input):
    domain = match_domain(user_input)
    if not domain:
        return None
    
    rss_feed_data = fetch_rss_feeds(domain)
    if rss_feed_data.empty:
        return None

    # Remove duplicates and preprocess summaries
    rss_feed_data = rss_feed_data.drop_duplicates()
    rss_feed_data['cleaned_summary'] = rss_feed_data['summary'].apply(preprocess_text)

    return rss_feed_data


# Function to post content to WordPress
def post_to_wordpress(title, content):
    headers = {
        "Authorization": f"Bearer {ACCESS_TOKEN}",
        "Content-Type": "application/json"
    }

    post_data = {
        "title": title,
        "content": content,
        "status": "draft"  # Change to 'publish' if you want the post to go live immediately
    }

    try:
        response = requests.post(WORDPRESS_URL, headers=headers, json=post_data)
        if response.status_code == 201:
            print(f"Post successfully created at {datetime.now()}")
        else:
            print(f"Failed to post to WordPress: {response.status_code} - {response.text}")
    except Exception as e:
        print(f"Error posting to WordPress: {e}")


# Scheduler job to generate content
def scheduled_post_generation():
    prompt = "Write a blog on gaming."
    content = generate_content(prompt)
    if content:
        scheduled_posts.append(content)
        print(f"Generated post: {content}")
    else:
        print("Failed to generate content.")

# Content generation using Azure model
def generate_content(prompt):
    try:
        messages = [
            SystemMessage(content="You are a helpful assistant."),
            UserMessage(content=prompt)
        ]
        response = client.complete(
            stream=True,
            messages=messages,
            model=model_name,
        )
        generated_content = ""
        for update in response:
            if update.choices:
                generated_content += update.choices[0].delta.content or ""
        return generated_content if generated_content else "No content generated."
    except Exception as e:
        print(f"Error generating content: {e}")
        return "Error generating content."

@app.route('/chat')
def chat():
    return render_template('chat.html')

# Route for scheduled posts page
@app.route('/sch')
def sch():
    return render_template('sch.html')

# Route to get the scheduled posts
@app.route('/get-scheduled-posts')
def get_scheduled_posts():
    return jsonify({"posts": scheduled_posts})

# Schedule the post generation function to run every minute
scheduler.add_job(func=scheduled_post_generation, trigger="interval", minutes=5)

@app.route('/schedule-post', methods=['POST'])
def schedule_post():
    data = request.json
    post_time = data.get('time')

    if not post_time:
        return jsonify({"error": "Time is required."}), 400

    try:
        # Parse the time from the user input
        scheduled_time = datetime.fromisoformat(post_time)

        # Calculate the delay for scheduling
        delay = (scheduled_time - datetime.now()).total_seconds()

        if delay < 0:
            return jsonify({"error": "Scheduled time must be in the future."}), 400

        # Schedule the job to run at the specified time
        scheduler.add_job(func=scheduled_post_generation, trigger='date', run_date=scheduled_time)

        return jsonify({"message": "Post scheduled successfully."}), 200
    except ValueError:
        return jsonify({"error": "Invalid date format."}), 400

# Routes
@app.route('/generate-content', methods=['POST'])
def generate_content_route():
    data = request.json
    user_domain = data.get('domain')
    user_prompt = data.get('prompt')

    if not user_domain or not user_prompt:
        return jsonify({"error": "Domain and prompt are required."}), 400

    matched_domain = match_domain(user_domain)
    if not matched_domain:
        return jsonify({"error": "No matching domain found."}), 400

    seo_content = generate_content(f"Provide structured SEO optimization tips for the topic: {user_prompt}")
    blog_content = generate_content(f"Write an SEO-optimized blog on the topic: {user_prompt} in the domain {user_domain}")
    social_media_post = generate_content(f"Create a social media post based on the blog topic: {user_prompt} in the domain {user_domain}")
    email_campaign = generate_content(f"Create a professional email campaign for the topic: {user_prompt} in the domain {user_domain}")

    return jsonify({
        "matched_domain": matched_domain,
        "seo_tips": seo_content,
        "blog_content": blog_content,
        "social_media_post": social_media_post,
        "email_campaign": email_campaign
    })

if __name__ == '__main__':
    app.run(debug=True)
